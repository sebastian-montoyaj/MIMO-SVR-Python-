{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cargo todas las librerias necesarias para el modelo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from __future__ import division\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Celda equivalente al archivo o funcion: scale.m\n",
    "def scale(X):\n",
    "    mu = np.amin(X, axis=0)\n",
    "    sig = np.amax(X, axis=0) - np.amin(X, axis=0)\n",
    "    X_Normal = (X - mu)/sig\n",
    "    \n",
    "    return X_Normal, mu, sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Celda equivalente al archivo o funcion: kernelmatrix.m\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# KERNELMATRIX\n",
    "#\n",
    "# K = kernelmatrix(ker,X,X2,parameter);\n",
    "#\n",
    "# Construye un kernel a partir de los datos de entrenamiento y validacion\n",
    "#\n",
    "# Entradas/Parametros: \n",
    "#      ker: {'lin' 'poly' 'rbf'}\n",
    "#      X: Matriz de datos con las muestras de entrenamiento en filas y las caracteristicas en columnas\n",
    "#      X2: Matriz de datos con las muestras de validacion en filas y las caracteristicas en columnas\n",
    "#      parameter: Depende el tipo de kernel a emplear, por lo que puede ser::\n",
    "#         El ancho del kernel RBF\n",
    "#         El termino independiente en el kernel lineal\n",
    "#         El grado del kernel polinomial\n",
    "#\n",
    "# Salida:\n",
    "#      K: kernel matrix\n",
    "#\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "def kernelmatrix(ker,X,X2,parameter):\n",
    "    if ker == 'lin':\n",
    "        if X2 is None:\n",
    "            K = np.dot(X.T, X/(np.linalg.norm(np.dot(X.T,X)))) + parameter # Aun me queda la duda\n",
    "            return K\n",
    "        else:\n",
    "            K = np.dot(X.T, X2/(np.linalg.norm(np.dot(X.T,X2)))) + parameter\n",
    "            return K\n",
    "            \n",
    "    elif ker == 'poly':        \n",
    "        if X2 is None:\n",
    "            K = (np.dot(X.T,X)/(np.linalg.norm(np.dot(X.T,X))) + 1)**parameter # Aun me queda la duda\n",
    "            return K\n",
    "        else:\n",
    "            K = (np.dot(X.T,X2)/(np.linalg.norm(np.dot(X.T,X2))) + 1)**parameter\n",
    "            return K\n",
    "           \n",
    "    elif ker == 'rbf':\n",
    "        \n",
    "        n1sq = np.sum(X**2, axis=0)\n",
    "        n1sq = np.atleast_2d(n1sq)\n",
    "        n1 = np.size(X,1)\n",
    "        \n",
    "        if n1 == 1: # Solo una caracteristica\n",
    "            N1 = np.size(X,0)\n",
    "            N2 = np.size(X2,0)\n",
    "            \n",
    "            D = np.zeros((N1,N2))\n",
    "            \n",
    "            for i in range(0, N1):\n",
    "                D[i,:] = (X2-np.ones((N2,1))*X[i,:]).T*(X2-np.ones((N2,1))*X[i,:]).T\n",
    "        else:\n",
    "            if X2 is None:\n",
    "                D = (np.ones((n1,1))*n1sq).T + np.ones((n1,1))*n1sq -2*np.dot(X.T,X)\n",
    "            else:\n",
    "                n2sq = np.sum(X2**2, axis=0)\n",
    "                n2sq = np.atleast_2d(n2sq)\n",
    "                n2 = np.size(X2,1)\n",
    "                \n",
    "                D = (np.ones((n2,1))*n1sq).T + np.ones((n1,1))*n2sq - 2*np.dot(X.T,X2)\n",
    "        \n",
    "        K = np.exp(-D**2/(2*(parameter**2)))\n",
    "        return K\n",
    "    else:\n",
    "        print \"ERROR kernel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Celda equivalente al archivo o funcion: msvr.m\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# SVR Multiples saliddas\n",
    "# Modelo que tiene m ejemplos de entrenamiento, d dimensiones(caracteristicas) y k salidas a predecir\n",
    "#\n",
    "# Entradas:   - x : muestras de entrenamiento (m x d),\n",
    "#             - y : salidas del sistema (m x k),\n",
    "#             - ker : tipo de kernel ('lin', 'poly', 'rbf'),\n",
    "#             - C : parametro de costo (boxConstraint),\n",
    "#             - par : parametro asociado al tipo de kernel (ver funcion 'kernelmatrix') ,\n",
    "#             - tol : tolerancia.\n",
    "#\n",
    "# Salidas:    - Beta : matriz o conjunto solucion con los parametros de la regresion,\n",
    "#             - NSV : numero de vectores de soporte,\n",
    "#             - H : kernel matrix,\n",
    "#             - i1 : indices de cuales muestras son los vectores de soporte.\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "def msvr(x,y,ker,C,epsi,par,tol):\n",
    "    n_m = np.size(x,0) # Obtengo el numero de muestras\n",
    "    n_d = np.size(x,1) # Obtengo el numero de caracteristicas del problema\n",
    "    n_k = np.size(y,1) # Obtengo el numero de salidas a predecir\n",
    "    \n",
    "    # Construyo la matriz kernel a partir de los muestras dadas \n",
    "    H = kernelmatrix(ker,x.T,x.T,par)\n",
    "    \n",
    "    # Creo una matriz para ir calculando iterativamente los parametros de la regresion\n",
    "    Beta = np.zeros((n_m,n_k))\n",
    "    \n",
    "    # E = Error de la prediccion por cada una de las salidas (Dimensiones: m x k)\n",
    "    E = y - np.dot(H,Beta)\n",
    "    u = np.sqrt(np.sum(E**2,1))\n",
    "\n",
    "    # RMSE (Raiz cuadrada del error)\n",
    "    RMSE = np.sqrt(np.mean(u**2))\n",
    "    \n",
    "    # Se obtienen los indices de aquellas muestras cuyo error de prediccion es mayor que epsilon\n",
    "    i1 = np.where(u>=epsi)[0]\n",
    "    \n",
    "    # Ahora, se establecen los valores iniciales de los alphas (terminos independientes)\n",
    "    a = 2*C*(u-epsi)/u\n",
    "    \n",
    "    # Creo un vector L  con dimensiones: 1 x m (L es el margen).\n",
    "    L = np.zeros(np.size(u))\n",
    "    \n",
    "    # Se modifican solo las muestras que cumplen que u > epsi\n",
    "    L[i1] = u[i1]**2 - 2*epsi*u[i1] + epsi**2\n",
    "    \n",
    "    #Lp es la cantidad a minimizar\n",
    "    Lp = sum(np.diag(np.dot(np.dot(Beta.T,H),Beta)))/2 + C*sum(L)/2\n",
    "    \n",
    "    eta   = 1\n",
    "    k     = 1\n",
    "    hacer = 1\n",
    "    val   = 1\n",
    "    \n",
    "    while hacer:\n",
    "        Beta_a = Beta\n",
    "        E_a = E\n",
    "        u_a = u\n",
    "        i1_a = i1\n",
    "        \n",
    "        M1 = (H[np.ix_(i1,i1)] + np.diag(1/a[i1])) + 1e-10*np.eye(len(a[i1]))\n",
    "        \n",
    "        # recalculo los betas\n",
    "        sal1 = np.dot(np.linalg.inv(M1),y[i1])\n",
    "\n",
    "        eta = 1\n",
    "        Beta = np.zeros(np.shape(Beta))\n",
    "        Beta[i1,:] = sal1\n",
    "        \n",
    "        # recalculo el error\n",
    "        E = y - np.dot(H,Beta)\n",
    "        \n",
    "        # RSE\n",
    "        u = np.sqrt(np.sum(E**2,1))\n",
    "        i1 = np.where(u>=epsi)[0]\n",
    "        \n",
    "        L = np.zeros(np.size(u))\n",
    "        \n",
    "        L[i1] = u[i1]**2 - 2*epsi*u[i1] + epsi**2\n",
    "        \n",
    "        # Se recalcula la funcion de perdida\n",
    "        Lp = np.append(Lp, sum(np.diag(np.dot(np.dot(Beta.T,H),Beta)))/2 + C*sum(L)/2)\n",
    "        \n",
    "        # Ciclo donde se guardaran los alphas y se modificaran los betas\n",
    "        while (Lp[k] > Lp[k-1]):\n",
    "            eta = eta/10\n",
    "            i1 = i1_a\n",
    "            \n",
    "            Beta = np.zeros(np.shape(Beta))\n",
    "            \n",
    "            # Los nuevos betas son una combinacion de los betas actuales (o sea, sal1) y\n",
    "            # los betas de la iteracion anterior (o sea, Beta_a)\n",
    "            Beta[i1] = eta*sal1 + (1-eta)*Beta_a[i1,:]\n",
    "            \n",
    "            E = y - np.dot(H,Beta)\n",
    "            u = np.sqrt(np.sum(E**2,1))\n",
    "            i1 = np.where(u>=epsi)[0]\n",
    "            \n",
    "            L = np.zeros(np.size(u))\n",
    "            L[i1] = u[i1]**2 - 2*epsi*u[i1] + epsi**2\n",
    "            Lp[k] = sum(np.diag(np.dot(np.dot(Beta.T,H),Beta)))/2 + C*sum(L)/2\n",
    "            \n",
    "            # Criterio de parada Num. 1\n",
    "            if(eta < 10**-16):\n",
    "                print \"Criterio de parada 1\"\n",
    "                Lp[k] = Lp[k-1] - 10**-15\n",
    "                Beta = Beta_a\n",
    "                #---------------\n",
    "                u = u_a\n",
    "                i1 = i1_a\n",
    "                #---------------\n",
    "                hacer = 0\n",
    "        \n",
    "        # Aqui modificamos(actualizamos) los alphas y guardamos los betas.\n",
    "        a_a = a        \n",
    "        a = 2*C*(u-epsi)/u\n",
    "        \n",
    "        RMSE = np.append(RMSE, np.sqrt(np.mean(u**2)))\n",
    "        \n",
    "        # Criterio de parada Num. 2\n",
    "        if((Lp[k-1]-Lp[k])/Lp[k-1]<tol):\n",
    "            print \"Criterio de parada 2\"\n",
    "            hacer = 0\n",
    "    \n",
    "        k = k + 1\n",
    "        \n",
    "        # Criterio de parada Num. 3 (Algoritmo no converge, por tanto: val = -1)\n",
    "        if(np.shape(i1)[0] == 0):\n",
    "            print \"Criterio de parada 3\"\n",
    "            hacer = 0\n",
    "            Beta = np.zeros(np.shape(Beta))\n",
    "            val = -1\n",
    "    \n",
    "    NSV = np.shape(i1)[0]\n",
    "\n",
    "    pred = np.dot(H,Beta)\n",
    "    \n",
    "    return Beta, NSV, H, i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Ejemplo de como se implementaria M-SVR ####\n",
    "\n",
    "# Aqui se cargan los datos de entrada y salida del sistema\n",
    "datosEntradas = pd.read_csv('Entradas_Reducidas.csv', usecols=range(3,71))\n",
    "archivoSalidas = pd.ExcelFile('Salidas.xlsx')\n",
    "datosSalidas = pd.read_excel(archivoSalidas, \"Sheet1\")\n",
    "\n",
    "# PARAMETROS del sistema\n",
    "C=10 # Parametro de regularización (boxConstraint)\n",
    "paramK=10 # Parametro para la funcion kernel\n",
    "tipoK='rbf' # Tipo de kernel a usar en el modelo. Los disponibles son: 'lin', 'poly' y 'rbf'\n",
    "epsilon = 1 # Parametro que establece el ancho del epsilon tubo o zona de tolerancia (por defecto es 1)\n",
    "tol=10**-20 # Parametro que necesita el modelo para detener el modelo si el error se vuelve muy bajo\n",
    "\n",
    "# Establezco el numero de pliegues (folds) con los que validare el sistema\n",
    "num_Subconjuntos = 10\n",
    "pliegues = KFold(len(datosEntradas), n_folds=num_Subconjuntos)\n",
    "\n",
    "# También creo varios arreglos de igual numero de espacios que iteraciones y en donde guardare los errores\n",
    "ECMTest = np.zeros((num_Subconjuntos,np.shape(datosSalidas)[1]))\n",
    "iteracion = 0\n",
    "\n",
    "# Ahora realizare tantas iteraciones como pliegues haya definido, donde:\n",
    "for train_index, test_index in pliegues:\n",
    "    # Selecciono los subconjuntos de entrenamiento y validacion para esta iteracion\n",
    "    X_train = datosEntradas.ix[train_index]\n",
    "    Y_train = datosSalidas.ix[train_index]\n",
    "    X_test = datosEntradas.ix[test_index]\n",
    "    Y_test = datosSalidas.ix[test_index]\n",
    "\n",
    "    # Se normalizan las X's\n",
    "    mu = np.mean(X_train, axis=0)\n",
    "    sigma = np.std(X_train, axis=0)\n",
    "    X_train = (X_train - mu)/sigma\n",
    "    X_test = (X_test - mu)/sigma\n",
    "\n",
    "    # Se remueve la media de las Y's (solo para el entrenamiento)\n",
    "    Ntrain = np.shape(X_train)[0]\n",
    "    mean_Y_train = np.mean(Y_train, axis=0)\n",
    "    Y_train = Y_train - np.matlib.repmat(mean_Y_train,Ntrain,1)\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    Beta, numero_VectoresS, kernel_train, indices_vectoresS = msvr(X_train.values,Y_train.values,tipoK,C,epsilon,paramK,tol)\n",
    "\n",
    "    # Predicción del modelo\n",
    "    kernel_test = kernelmatrix(tipoK,X_test.T,X_train.T,paramK)\n",
    "    Ntest = np.shape(X_test)[0]\n",
    "    b = np.matlib.repmat(mean_Y_train,Ntest,1)\n",
    "    Y_est = np.dot(kernel_test,Beta) + b\n",
    "\n",
    "    # Medicion de ECM\n",
    "    ECMTest[iteracion] = (np.sum((Y_est-Y_test.values), axis=0)**2)/np.shape(Y_test)[0]\n",
    "\n",
    "    print \"El ECM de la iteracion No.\", iteracion+1, \" fue = \", ECMTest[iteracion]\n",
    "    print \"Y el numero de vectores de soporte usados fue = \", numero_VectoresS, \" de \", Ntrain, \"\\n\"\n",
    "\n",
    "    iteracion = iteracion + 1\n",
    "\n",
    "# Finalmente, muestro los resultados finales\n",
    "\n",
    "mean_ECM = np.mean(ECMTest,axis=0)\n",
    "ic_ECM = np.std(ECMTest,axis=0)\n",
    "\n",
    "print \"El error cuadratico medio obtenido para cada salida es: \", mean_ECM, \"±\", ic_ECM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
